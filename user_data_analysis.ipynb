{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking User Behavior in our Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#copy the YAML file and game_api.py file into our working directory\n",
    "\n",
    "cp ~/w205/course-content/13-Understanding-Data/docker-compose.yml ~/w205/project-3-jchung738/\n",
    "cp ~/w205/course-content/11-Storing-Data-III/game_api.py .\n",
    "\n",
    "#start the cluster, create a topic events and shut down the cluster\n",
    "\n",
    "docker-compose up -d\n",
    "docker-compose exec kafka kafka-topics --create --topic events --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "\n",
    "#start up the Flask server\n",
    "\n",
    "docker-compose exec mids env FLASK_APP=/w205/project-3-jchung738/game_api.py flask run --host 0.0.0.0\n",
    "\n",
    "#use Apache Bench commands to send events to our server from 2 users\n",
    "\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/buy_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/join_a_guild\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/purchase_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/buy_a_sword\n",
    "docker-compose exec mids ab -n 10 -H \"Host: user2.att.com\" http://localhost:5000/join_a_guild\n",
    "\n",
    "#check with Kafkacat to confirm the events are received\n",
    "\n",
    "docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning -e\n",
    "\n",
    "#start pyspark kernel and link to Jupyter notebook\n",
    "\n",
    "docker-compose exec spark bash\n",
    "ln -s /w205 w205\n",
    "exit\n",
    "docker-compose exec spark env PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --no-browser --port 8888 --ip 0.0.0.0 --allow-root' pyspark\n",
    "\n",
    "#external IP\n",
    "\n",
    "35.247.16.198\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in events using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import json\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@udf('string')\n",
    "def munge_event(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    event['Host'] = \"moe\"\n",
    "    event['Cache-Control'] = \"no-cache\"\n",
    "    return json.dumps(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load raw events with spark\n",
    "raw_events = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "| key|               value| topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     0|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     1|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     2|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     3|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     4|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     5|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     6|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     7|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     8|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     9|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    10|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    11|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    12|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    13|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    14|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    15|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    16|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    17|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    18|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    19|2020-12-07 17:33:...|            0|\n",
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " #transform the data into strings\n",
    "    \n",
    "munged_events = raw_events \\\n",
    "    .select(raw_events.value.cast('string').alias('raw'),\n",
    "            raw_events.timestamp.cast('string')) \\\n",
    "    .withColumn('munged', munge_event('raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                 raw|           timestamp|              munged|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "|{\"Host\": \"user1.c...|2020-12-07 17:33:...|{\"Host\": \"moe\", \"...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "munged_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract events with lambda transform\n",
    "extracted_events = munged_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.munged))) \\\n",
    "        .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accept: string (nullable = true)\n",
      " |-- Cache-Control: string (nullable = true)\n",
      " |-- Host: string (nullable = true)\n",
      " |-- User-Agent: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_events.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter for only purchase_sword events\n",
    "\n",
    "sword_purchases = extracted_events \\\n",
    "        .filter(extracted_events.event_type == 'purchase_sword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accept: string (nullable = true)\n",
      " |-- Cache-Control: string (nullable = true)\n",
      " |-- Host: string (nullable = true)\n",
      " |-- User-Agent: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sword_purchases.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#boolean function to select for purchase_sword events\n",
    "@udf('boolean')\n",
    "def is_purchase(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#boolean function to select for join_a_guild events\n",
    "\n",
    "@udf('boolean')\n",
    "def is_guild(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'join_a_guild':\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the events using spark\n",
    "raw_events = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "| key|               value| topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     0|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     1|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     2|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     3|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     4|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     5|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     6|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     7|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     8|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|     9|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    10|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    11|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    12|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    13|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    14|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    15|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    16|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    17|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    18|2020-12-07 17:33:...|            0|\n",
      "|null|[7B 22 48 6F 73 7...|events|        0|    19|2020-12-07 17:33:...|            0|\n",
      "+----+--------------------+------+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter using spark with the boolean function is_purchase\n",
    "purchase_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .filter(is_purchase('raw'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter using spark with the boolean function is_guild\n",
    "\n",
    "guild_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .filter(is_guild('raw'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "RDD is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7f4dfbd4b5bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Use lambda transforms to turn the data into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mextracted_guild_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguild_events\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/spark-2.2.0-bin-hadoop2.6/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mtoDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampleRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark-2.2.0-bin-hadoop2.6/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark-2.2.0-bin-hadoop2.6/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \"\"\"\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark-2.2.0-bin-hadoop2.6/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \"\"\"\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             raise ValueError(\"The first row in RDD is empty, \"\n",
      "\u001b[0;32m/spark-2.2.0-bin-hadoop2.6/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RDD is empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0misEmpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: RDD is empty"
     ]
    }
   ],
   "source": [
    "#Use lambda transforms to turn the data into a DataFrame \n",
    "extracted_guild_events = guild_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "        .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Use lambda transforms to turn the data into a DataFrame \n",
    "\n",
    "extracted_purchase_events = purchase_events \\\n",
    "    .rdd \\\n",
    "    .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accept: string (nullable = true)\n",
      " |-- Host: string (nullable = true)\n",
      " |-- User-Agent: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- sword_type: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    extracted_purchase_events.printSchema()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|  event_type|guild_type|           timestamp|\n",
      "+------+-----------------+---------------+------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable| 2020-12-07 16:40:35|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "+------+-----------------+---------------+------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_guild_events.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|    event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    extracted_purchase_events.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the DataFrames into parquet\n",
    "extracted_guild_events\\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('/tmp/guilds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the DataFrames into parquet\n",
    "\n",
    "extracted_purchase_events \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet('/tmp/purchases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Parquet files from HDFS to be queried against with SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read parquet from tmp directory\n",
    "purchases = spark.read.parquet('/tmp/purchases')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read parquet from tmp directory\n",
    "\n",
    "guilds = spark.read.parquet('/tmp/guilds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|    event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|  event_type|guild_type|           timestamp|\n",
      "+------+-----------------+---------------+------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable| 2020-12-07 16:40:35|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "|   */*|    user2.att.com|ApacheBench/2.3|join_a_guild|roundtable|2020-12-07 16:40:...|\n",
      "+------+-----------------+---------------+------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guilds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#register the parquet as a temp table for SQL queroes\n",
    "guilds.registerTempTable('guilds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#register the parquet as a temp table for SQL queroes\n",
    "\n",
    "purchases.registerTempTable('purchases')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SQL query\n",
    "\n",
    "purchases_by_example2 = spark.sql(\"select * from purchases where Host = 'user1.comcast.com'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|Accept|             Host|     User-Agent|    event_type|sword_type|           timestamp|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword| longsword|2020-12-07 16:40:...|\n",
      "+------+-----------------+---------------+--------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases_by_example2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save query as Pandas DataFrame\n",
    "df = purchases_by_example2.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accept</th>\n",
       "      <th>Host</th>\n",
       "      <th>User-Agent</th>\n",
       "      <th>event_type</th>\n",
       "      <th>sword_type</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>*/*</td>\n",
       "      <td>user1.comcast.com</td>\n",
       "      <td>ApacheBench/2.3</td>\n",
       "      <td>purchase_sword</td>\n",
       "      <td>longsword</td>\n",
       "      <td>2020-12-07 00:30:38.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accept               Host       User-Agent      event_type sword_type  \\\n",
       "count      10                 10               10              10         10   \n",
       "unique      1                  1                1               1          1   \n",
       "top       */*  user1.comcast.com  ApacheBench/2.3  purchase_sword  longsword   \n",
       "freq       10                 10               10              10         10   \n",
       "\n",
       "                      timestamp  \n",
       "count                        10  \n",
       "unique                       10  \n",
       "top     2020-12-07 00:30:38.117  \n",
       "freq                          1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What size is the Roundtable guild?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SQL query\n",
    "\n",
    "roundtable = spark.sql(\"select count(*) from guilds where guild_type ='roundtable'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      20|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roundtable.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 20 users that joined the Roundtable guild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roundtable_df = roundtable.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(1)\n",
       "0        20"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roundtable_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times has a longsword been purchased?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SQL query\n",
    "\n",
    "longsword = spark.sql(\"select count(Host) from purchases where sword_type = 'longsword'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(Host)|\n",
      "+-----------+\n",
      "|         20|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longsword.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longsword has been purchased 20 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in a Stream of Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#infinite loop for Apache Bench to send tests to our server\n",
    " \n",
    "while true; do docker-compose exec mids ab -n 10 -H \"Host: user1.comcast.com\" http://localhost:5000/purchase_a_sword; sleep 5; done\n",
    "\n",
    "#startup hive to create schema on read\n",
    "\n",
    "docker-compose exec cloudera hive\n",
    "\n",
    "#hive command to create an external table for schema on read\n",
    "\n",
    "create external table if not exists default.sword_purchases (Accept string, Host string, User_Agent string, event_type string, timestamp string) stored as parquet location '/tmp/sword_purchases'  tblproperties (\"parquet.compress\"=\"SNAPPY‚Äù);\n",
    "exit;\n",
    "\n",
    "#Start up Presto\n",
    "\n",
    "docker-compose exec presto presto --server presto:8080 --catalog hive --schema default\n",
    "\n",
    "#Query against the external table using Presto commands\n",
    "\n",
    "select * from sword_purchases;\n",
    "select count(*) from sword_purchases;\n",
    "exit;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.functions import udf, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#enforce schema for spark\n",
    "\n",
    "def purchase_sword_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#boolean function to select for purchase_sword events\n",
    "\n",
    "@udf('boolean')\n",
    "def is_sword_purchase(event_as_json):\n",
    "    \"\"\"udf for filtering events\n",
    "    \"\"\"\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in event using spark\n",
    "raw_events = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#enforce schema with our  purchase_sword_event_schema function\n",
    "sword_purchases = raw_events \\\n",
    "        .filter(is_sword_purchase(raw_events.value.cast('string'))) \\\n",
    "        .select(raw_events.value.cast('string').alias('raw_event'),\n",
    "                raw_events.timestamp.cast('string'),\n",
    "                from_json(raw_events.value.cast('string'),\n",
    "                          purchase_sword_event_schema()).alias('json')) \\\n",
    "        .select('raw_event', 'timestamp', 'json.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write hdfs files in streaming mode\n",
    "    sink = sword_purchases \\\n",
    "        .writeStream \\\n",
    "        .format(\"parquet\") \\\n",
    "        .option(\"checkpointLocation\", \"/tmp/checkpoints_for_sword_purchases\") \\\n",
    "        .option(\"path\", \"/tmp/sword_purchases\") \\\n",
    "        .trigger(processingTime=\"10 seconds\") \\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stop writing the hdfs files\n",
    "sink.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#shutdown the cluster\n",
    "\n",
    "docker-compose down"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
